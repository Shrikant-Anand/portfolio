---
title: <span style="color:#0000FF">"Preprocessing of data"</span>
author: <span style="color:#0000FF">"Shrikant Anand"</span>
date: "12/03/2023"
output: 
  html_document:
    theme: yeti
    highlight: tango
    fig_width: 8
    fig_height: 7
    fig_caption: true
    code_folding: hide
    number_sections: true
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{=html}
<style>
body {text-align: justify}
</style>
```
# - [Enunciado del ejercicio]{style="color:#D35400"}

Un banco quiere disponer de un modelo de credit scoring para lo cual dispone de un conjunto de datos con 1.646 registros de clientes a los que concedió un crédito.
Esta base de datos contiene siete variables numéricas y cuatro categóricas.
La variable denominada CLASE muestra la información de si el cliente devolvió el crédito o no y toma dos valores: SI y NO.

La descripción de la base de datos es la siguiente:

**TIPO_VIVIENDA**: Propiedad libre, Propiedad hipotecada, Alquiler, Vive con la familia y Otros.

**VALOR_VIVIENDA**: Valor de la vivienda.

**PATRIMONIO**: Montante del patrimonio.

**NACIONALIDAD**: Español y Extranjero.

**IMPORTE**: Importe del préstamo.

**CUOTA**: Cuota que paga al banco por el préstamo concedido.

**INGRESOS**: Ingresos del peticionario del crédito.

**SALDO**: Saldo que mantiene en la cuenta bancaria.

**EDAD**: Edad.

**ESTADO_CIVIL**: Esta variable toma tres valores: Casado, Separado y Soltero.

**CLASE**: Muestra dos valores, No para los que no pagaron el crédito y SI para los clientes que sí cumplieron con el pago del crédito.

# - [Librerías y base de datos]{style="color:#D35400"}

Instalamos los paquetes que necesitaremos durante nuestro análisis.

```{r librerias, message=FALSE, warning=FALSE}


rm(list = ls())

suppressWarnings(suppressPackageStartupMessages({
  
  library(skimr)
  library(funModeling)
  library(inspectdf) 
  library(DataExplorer) 
  library(PerformanceAnalytics) 
  library(corrplot) 
  library(flextable)
  library(kableExtra)
  library(officer)
  library(rmarkdown)
  library(magrittr)
  library(tidyverse) 
  library(patchwork)  
  library(ggthemes)
  library(ggpubr) 
  library(data.table) 
  library(fastDummies)
  library(naniar)
  library(mice)
  library(VIM)
  library(gmodels) 
  library(dlookr) 
  library(randomForest) 
  library(dlookr)
  library(sampling) 
  library(DMwR)
  library(car)
}))

```

<h4 style="color:#0000FF">

Lectura de la base de datos and convirtiéndolo en un data.table.

</h4>

```{r}
datos = read.csv("datos_credit_scoring.csv")
datos = as.data.table(datos)
```

# - [Análisis descriptivo]{style="color:#D35400"}

<h4 style="color:#0000FF">

Descripción de la base de datos

</h4>

Vemos la estructura de nuestra base de datos:

```{r}
str(datos)
```

Buscamos entradas duplicadas y vemos que no hay ninguna.

```{r}
anyDuplicated(datos)
```

Convertimos las variables de tipo carácter a factores.

```{r}
datos$TIPO_VIVIENDA = as.factor(datos$TIPO_VIVIENDA)
datos$NACIONALIDAD = as.factor(datos$NACIONALIDAD)
datos$ ESTADO_CIVIL = as.factor(datos$ ESTADO_CIVIL)
datos$CLASE = as.factor(datos$CLASE)

```


Vemos las primeras filas:

```{r}
head(datos)
```

```{r}
str(datos)
```


<h4 style="color:#0000FF">

Resumen estadístico

</h4>

Comenzamos con el comando summary(), que nos da las magnitudes básicas de cada variable.

```{r}
summary(datos)
```

Utilizamos el comando skim(), obtenemos más información útil, como el número de valores que faltan, los valores únicos en el caso de las variables cualitativas, los valores medios y la desviación típica en el caso de las variables numéricas.

```{r}
skim(datos)
```


La función skim() nos ha mostrado que faltan algunos valores en nuestro conjunto de datos.
Veámoslos con algunos métodos más.

```{r}
colSums(is.na(datos))
```

```{r}
sapply(datos, function(x) sum(is.na(x)))
```

```{r}
sum(is.na(datos))
```

Hemos visto algunos detalles estadísticos utilizando summary() y skim().
Ahora usando la librería funmodeling, usaremos algunas funciones más para obtener detalles similares.

```{r}
status(datos)
```

Utilizando el comando profiling_num(), obtenemos las estadísticas anteriores, pero además de eso obtenemos algunos detalles más, como el rango,inter-quartile range,skewness y kurtosis.

```{r}
profiling_num(datos)

```

La función plot_num() nos permite visualizar histogramas de variables numéricas.

```{r}
plot_num(datos)
```

Visualización de variables categóricas por frecuencia:

```{r}
freq(datos)
```

Aquí vemos gráficos de caja de diferentes variables.

```{r}
plotar(datos, target= "CLASE", plot_type="boxplot")
```

Hemos visto los tipos de variables y hemos comprobado si hay filas duplicadas y, si hay NAs en nuestro conjunto de datos.Hemos visto los valores únicos en cada columna, la media y el rango en el caso de variables numéricas.También, hemos visto las ocurrencias de cada factor en la tabla de frecuencias y finalmente, hemos visto los gráficos de caja de cada variable por su CLASE.

Ahora veremos algunos estadísticos de variables categóricas y cómo se comportan con la variable de clase CLASE.

```{r}
categoricas <- datos %>% select (TIPO_VIVIENDA,NACIONALIDAD,ESTADO_CIVIL,CLASE)

categ_analysis(categoricas, target = 'CLASE')
```

```{r}
cross_plot(categoricas, target = 'CLASE', auto_binning = TRUE )
```

# - [Análisis de correlaciones]{style="color:#D35400"}

Ahora vamos a ver cómo se comportan las variables entre sí y con nuestra variable objetivo "CLASE".
También intentaremos averiguar qué variables explican la variable CLASE mucho mejor que otras.

<h4 style="color:#0000FF">

Tablas de correspondencias y gráficos

</h4>

```{r}
#creamos un conjunto de datos con sólo variables numéricas y sin NAs.
datos_num = subset(na.omit(datos), select = c("VALOR_VIVIENDA","PATRIMONIO","IMPORTE","CUOTA","INGRESOS","SALDO","EDAD"))
```

Creación de una matriz de correlaciones:

```{r}
corr_datos_num = as.data.frame((cor(datos_num)))
round(corr_datos_num,2)
```

Mejores formas de visualizar las correlaciones:

```{r}
correlaciones <- round(cor(datos_num), 1)
corrplot(correlaciones, method="number", type="upper")
```

```{r}
chart.Correlation(datos_num, histogram = F, pch=19)
```

Los valores de la tabla representan el grado de correlación entre pares de variables.
Los valores van de -1 a 1, donde -1 representa una correlación negativa perfecta, 0 representa ninguna correlación y 1 representa una correlación positiva perfecta.
Esta tabla nos da la correlación entre cada par de variables, con el tamaño de letra en función del grado de correlación, así como un conjunto de 0 a 3 estrellas, que indica la importancia de la correlación, de menor a mayor.

Observando la tabla, podemos ver que IMPORTE y CUOTA están fuertemente correlacionados positivamente, con un coeficiente de correlación de 0,91.
El coeficiente de correlación entre "VALOR_VIVIENDA" y "EDAD" es de 0,37, lo que indica una correlación positiva entre estas dos variables, al igual que la correlación de 0,32 entre "VALOR_VIVIENDA" e "INGRESOS".
Ninguna de las variables tiene una correlación negativa entre sí y la mayoría de ellas tienen una correlación positiva y significativa.

Otra forma de ver las correlaciones es utilizando la función plot_correlation.
Cuanto más oscuro sea el color, más correlacionadas estarán las variables.

```{r}
plot_correlation(datos_num)
```

Calculamos el nivel de significación de las diferentes correlaciones (p-value):

```{r}
correlacion_pvalue = cor.mtest(datos_num, conf.level=0.95)$p

rownames(correlacion_pvalue) = rownames(correlacion_pvalue)
colnames(correlacion_pvalue) = colnames(correlacion_pvalue)
```

La matriz resultante muestra los valores p de las correlaciones entre las variables numéricas.
Los valores de la diagonal son todos 0, ya que la correlación entre una variable consigo misma es siempre 1.
Los demás valores de la matriz representan los valores p de las correlaciones entre pares de variables.
Por ejemplo, el valor p de la correlación entre VALOR_VIVIENDA y PATRIMONIO es 0, lo que indica una correlación significativa al nivel de significación de 0,05.
Del mismo modo, el valor p de la correlación entre VALOR_VIVIENDA e IMPORTE es 0, lo que indica una correlación significativa al nivel de significación 0,05.
El valor p de la correlación entre SALDO y PATRIMONIO es 0,3203, lo que indica una correlación no significativa al nivel de significación de 0,05.

```{r}
# si p-value < 0,05 el valor es significativo
round(correlacion_pvalue,4)
```

Utilizaremos la librería inspectdb para generar los coeficientes de correlación de Pearson, el p-value y los intervalos de confianza.

La tabla siguiente muestra las correlaciones entre pares de variables utilizando datos_num.
También muestra los valores p, los límites inferior y superior del intervalo de confianza y el porcentaje de valores no ausentes para cada correlación.

La correlación positiva más fuerte es la existente entre CUOTA e IMPORTE, con un coeficiente de correlación de 0,91.

Hay varias correlaciones con valores p inferiores a 0,05, lo que indica una correlación estadísticamente significativa.

```{r}
 x <- inspect_cor(datos_num)
 x1 <- as.data.frame(x)
 paged_table(x1)
```

Aquí puede verse una buena visualización de los coeficientes de correlación por pares.

```{r}
 show_plot(x)
```

# - [Tablas de datos]{style="color:#D35400"}

Ahora vamos a observar algunas tablas de datos y centrar nuestro análisis en variables categóricas, que nos ayuden a comprender si existe alguna asociación o patrón entre nuestras variables a la hora de explicar nuestra variable objetivo CLASE.

```{r}
table(datos$CLASE)
```

```{r}
round(prop.table(table(datos$CLASE)),2)
```

<h4 style="color:#0000FF">

Contraste tabla de contingencia.

</h4>

Creamos una tabla de contingencia de TIPO_VIVIENDA y CLASE.
El resultado muestra que el estadístico chi-cuadrado de Pearson es 221,76 con 4 grados de libertad y un p valor inferior a 2,2e-16.
Esto indica que existe una asociación significativa entre TIPO_VIVIENDA y CLASE.

```{r}
t1 <- table(datos$TIPO_VIVIENDA,datos$CLASE)
addmargins(t1)


```

```{r}
chisq.test(t1)
```

La siguiente tabla es entre las variables NACIONALIDAD y CLASE.
Aquí utilizaremos CrossTable() de la librería gmodels en formato SPSS para una mejor visualización de los resultados.
Como podemos ver, el valor p es muy pequeño proporcionando una fuerte evidencia contra la hipótesis nula de independencia entre las dos variables.

```{r}
t2 <- table(datos$NACIONALIDAD,datos$CLASE)
addmargins(t2)
```

```{r}
CrossTable(t2, expected = TRUE, format="SPSS")
```

Ahora observamos la variable ESTADO_CIVIL con CLASE.
Aquí también el valor p es muy inferior a 0,05, lo que sugiere una fuerte asociación entre las dos variables.

```{r}
t3 <- table(datos$ESTADO_CIVIL,datos$CLASE)
addmargins(t3)
```

```{r}
CrossTable(t3, expected = TRUE, format="SPSS")
```

Ahora utilizaremos variables cuantitativas en nuestro análisis para crear diferentes tablas por CLASE y obtener una buena visión de algunos números.

```{r}


table1 <- datos %>%
  group_by(CLASE) %>%
  summarize(VALOR_VIVIENDA_Media = mean(VALOR_VIVIENDA, na.rm = TRUE),
            PATRIMONIO_Media = mean(PATRIMONIO, na.rm = TRUE),
            IMPORTE_Media = mean(IMPORTE, na.rm = TRUE),
            CUOTA_Media = mean(CUOTA, na.rm = TRUE),
            INGRESOS_Media = mean(INGRESOS, na.rm = TRUE),
            SALDO_Media = mean(SALDO, na.rm = TRUE),
            EDAD_Media = mean(EDAD, na.rm = TRUE)) %>%
  mutate(CLASE = factor(CLASE, levels = c("SI", "NO")))

# dar formato a la tabla utilizando flextable 
table1 = flextable(table1) %>%
  colformat_double(big.mark = ".",decimal.mark = ",",digits =2)%>%
  add_header_lines(values = "Valor de la media en función del tipo de cliente*")%>% 
  add_footer_lines(values = "Tipo de cliente ='SI',pagaron el crédito., 'NO',no pagaron el crédito")%>%
  color(color = "#993399", part = "header")%>%
  color(color = "chocolate4", part = "body")%>%
  color(color = "grey", part = "footer")%>%
  autofit()%>%
  align(align = "center", part = "all")

table1
```

```{r}

table2 <- datos %>%
  group_by(TIPO_VIVIENDA, CLASE) %>%
  summarise(mean_VALOR_VIVIENDA = mean(VALOR_VIVIENDA, na.rm = TRUE),
            PATRIMONIO_Media = mean(PATRIMONIO, na.rm = TRUE),
            IMPORTE_Media = mean(IMPORTE, na.rm = TRUE),
            CUOTA_Media = mean(CUOTA, na.rm = TRUE),
            INGRESOS_Media = mean(INGRESOS, na.rm = TRUE),
            SALDO_Media = mean(SALDO, na.rm = TRUE),
            EDAD_Media = mean(EDAD, na.rm = TRUE))
# dar formato a la tabla utilizando kablextra 
  kable_styling(kable(table2,
                    format ="html",
                    digits = c(NA,NA,2,2,2,2,2,2,2),
                    format.args = list(decimal.mark = ",", big.mark = "."),
                    row.names = F,
                    align = c("l","c","c","c","c"),
                    booktabs = T,
                    caption = "Tabla de TIPO_VIVIENDA con CLASE",
              latex_options = c("striped","condensed"),
              position = "center",
              full_width = F))

```

```{r}
table3 <- datos %>%
  group_by(NACIONALIDAD, CLASE) %>%
  summarise(mean_VALOR_VIVIENDA = mean(VALOR_VIVIENDA, na.rm = TRUE),
            PATRIMONIO_Media = mean(PATRIMONIO, na.rm = TRUE),
            IMPORTE_Media = mean(IMPORTE, na.rm = TRUE),
            CUOTA_Media = mean(CUOTA, na.rm = TRUE),
            INGRESOS_Media = mean(INGRESOS, na.rm = TRUE),
            SALDO_Media = mean(SALDO, na.rm = TRUE),
            EDAD_Media = mean(EDAD, na.rm = TRUE))

  kable_styling(kable(table3,
                    format ="html",
                    digits = c(NA,NA,2,2,2,2,2,2,2),
                    format.args = list(decimal.mark = ",", big.mark = "."),
                    row.names = F,
                    align = c("l","c","c","c","c"),
                    booktabs = T,
                    caption = "Tabla de NACIONALIDAD con CLASE",
              latex_options = c("striped","condensed"),
              position = "center",
              full_width = F))

```

```{r}
table4 <- datos %>%
  group_by(ESTADO_CIVIL, CLASE) %>%
  summarise(mean_VALOR_VIVIENDA = mean(VALOR_VIVIENDA, na.rm = TRUE),
            PATRIMONIO_Media = mean(PATRIMONIO, na.rm = TRUE),
            IMPORTE_Media = mean(IMPORTE, na.rm = TRUE),
            CUOTA_Media = mean(CUOTA, na.rm = TRUE),
            INGRESOS_Media = mean(INGRESOS, na.rm = TRUE),
            SALDO_Media = mean(SALDO, na.rm = TRUE),
            EDAD_Media = mean(EDAD, na.rm = TRUE))

  kable_styling(kable(table4,
                    format ="html",
                    digits = c(NA,NA,2,2,2,2,2,2,2),
                    format.args = list(decimal.mark = ",", big.mark = "."),
                    row.names = F,
                    align = c("l","c","c","c","c"),
                    booktabs = T,
                    caption = "Tabla de ESTADO_CIVIL con CLASE",
              latex_options = c("striped","condensed"),
              position = "center",
              full_width = F))
```

# - [Análisis gráfico]{style="color:#D35400"}

Podemos utilizar varios métodos de representación gráfica de las variables independientes para comprender su influencia en la variable dependiente.
Utilizaremos diferentes estilos como diagramas de barras, diagramas de dispersión, histogramas, diagramas de caja.
Para ello, utilizaremos gráficos de la librería ggplot2 que ofrece múltiples formas para representar información gráficamente.

Definiremos una función para crear gráficos de dispersión.
Lo visualizaremos según los niveles de la variable dependiente.
También se añade una línea de tendencia general que muestra el intervalo de confianza.

```{r}
graf_dispersion <- function(var1,var2){
  dat <- datos[, c(var1, var2, "CLASE"), with = FALSE]
  ggplot(data = dat, aes_string(x = var1, y = var2)) +
    geom_point(aes_string(col = "CLASE")) +
    geom_smooth() +
    ggtitle('Gráfico Scatter Plot') +
    theme(plot.title = element_text(color = "blue", hjust = 0.5)) +
    labs(x = var1, y = var2)  
}
```

```{r}
graf_dispersion("IMPORTE","INGRESOS")
```

```{r}
graf_dispersion("SALDO","EDAD")
```

```{r}
graf_dispersion("VALOR_VIVIENDA","PATRIMONIO")
```

Algunos gráficos con histogramas:

```{r}
hist1 = ggplot(datos, aes(x = IMPORTE)) +
  geom_histogram(aes(y=..density..), colour="black", fill = "lightblue") +
  geom_density(alpha = .2, fill = "#FF6666") +
  ggtitle("Histograma IMPORTE") +
  theme(plot.title = element_text(color = "black")) +
  facet_grid(CLASE ~.)
hist1
```

```{r}
hist1 = ggplot(datos, aes(x = INGRESOS)) +
  geom_histogram(aes(y=..density..), colour="black", fill = "lightblue") +
  geom_density(alpha = .2, fill = "#FF6666") +
  ggtitle("Histograma INGRESOS") +
  theme(plot.title = element_text(color = "black")) +
  facet_grid(CLASE ~.)
hist1
```

```{r}
hist1 = ggplot(datos, aes(x = EDAD)) +
  geom_histogram(aes(y=..density..), colour="black", fill = "lightblue") +
  geom_density(alpha = .2, fill = "#FF6666") +
  ggtitle("Histograma EDAD") +
  theme(plot.title = element_text(color = "black")) +
  facet_grid(CLASE ~.)
hist1
```

Ahora utilizamos el diagrama de cajas para cada variable numérica independiente frente a la variable dependiente categórica CLASE (NO y SI) y, añadimos una comparación estadística de medias utilizando una prueba t.
El gráfico muestra la distribución de la variable independiente para cada grupo y nos permite comparar las medianas, los cuartiles y el rango de los dos grupos.
La comparación estadística indica si existe una diferencia significativa entre las medias de los dos grupos.

```{r}
#  Diagramas de cajas (con p-value para el contraste t de student)
# variable VALOR_VIVIENDA
ggplot(data = datos, aes(x = CLASE, y= VALOR_VIVIENDA)) +
  geom_boxplot(color = 'darkorchid4') + 
  ggtitle("Box Plot entre CLASE y VALOR_VIVIENDA")+ 
  stat_compare_means(comparisons = list(c("NO", "SI")), method = "t.test")
```

Para entender correctamente si las varianzas de los grupos son iguales o no y para sacar conclusiones sobre la significación del gráfico anterior, realizaremos una prueba de homogeneidad de varianzas.
Utilizaremos dos pruebas porque en algunos casos pueden dar valores p diferentes (aunque podemos utilizar cualquiera).

La prueba de Levene es una prueba paramétrica que comprueba si las varianzas de los grupos son iguales.
Supone que los datos se distribuyen normalmente, y el estadístico de la prueba se basa en las desviaciones absolutas de los datos respecto a las medias de los grupos.
Un resultado significativo (valor p \< 0,05) sugiere que las varianzas son diferentes, lo que viola el supuesto de homogeneidad de la varianza.

La prueba de Fligner-Killeen es una alternativa no paramétrica a la prueba de Levene.
Se basa en las medianas de las desviaciones absolutas de las medianas de grupo, lo que la hace más robusta a las desviaciones de la normalidad.
Al igual que la prueba de Levene, un resultado significativo sugiere que las varianzas de los grupos son diferentes.

```{r}
fligner.test(VALOR_VIVIENDA ~ CLASE, data = datos)
```

```{r}
leveneTest(VALOR_VIVIENDA ~ CLASE, data = datos, center = "median")
```

```{r}
# variable PATRIMONIO
ggplot(data = datos, aes(x = CLASE, y= PATRIMONIO)) +
  geom_boxplot(color = 'darkorchid4') + 
  ggtitle("Box Plot entre CLASE y PATRIMONIO")+ 
  stat_compare_means(comparisons = list(c("NO", "SI")), method = "t.test")
```

```{r}
fligner.test(PATRIMONIO ~ CLASE, data = datos)
```

```{r}
leveneTest(PATRIMONIO ~ CLASE, data = datos, center = "median")
```

```{r}
# variable IMPORTE
ggplot(data = datos, aes(x = CLASE, y= IMPORTE)) +
  geom_boxplot(color = 'darkorchid4') + 
  ggtitle("Box Plot entre CLASE y IMPORTE")+ 
  stat_compare_means(comparisons = list(c("NO", "SI")), method = "t.test")
```

```{r}
fligner.test(IMPORTE ~ CLASE, data = datos)
```

```{r}
leveneTest(IMPORTE ~ CLASE, data = datos, center = "median")
```

```{r}
# variable CUOTA
ggplot(data = datos, aes(x = CLASE, y= CUOTA)) +
  geom_boxplot(color = 'darkorchid4') + 
  ggtitle("Box Plot entre CLASE y CUOTA")+ 
  stat_compare_means(comparisons = list(c("NO", "SI")), method = "t.test")
```

```{r}
fligner.test(CUOTA ~ CLASE, data = datos)
```

```{r}
leveneTest(CUOTA ~ CLASE, data = datos, center = "median")
```

```{r}
# variable INGRESOS
ggplot(data = datos, aes(x = CLASE, y= INGRESOS)) +
  geom_boxplot(color = 'darkorchid4') + 
  ggtitle("Box Plot entre CLASE y INGRESOS")+ 
  stat_compare_means(comparisons = list(c("NO", "SI")), method = "t.test")
```

```{r}
fligner.test(INGRESOS ~ CLASE, data = datos)
```

```{r}
leveneTest(INGRESOS ~ CLASE, data = datos, center = "median")
```

```{r}
# variable SALDO
ggplot(data = datos, aes(x = CLASE, y= SALDO)) +
  geom_boxplot(color = 'darkorchid4') + 
  ggtitle("Box Plot entre CLASE y SALDO")+ 
  stat_compare_means(comparisons = list(c("NO", "SI")), method = "t.test")
```

```{r}
fligner.test(SALDO ~ CLASE, data = datos)
```

```{r}
leveneTest(SALDO ~ CLASE, data = datos, center = "median")
```

```{r}
# variable EDAD
ggplot(data = datos, aes(x = CLASE, y= EDAD)) +
  geom_boxplot(color = 'darkorchid4') + 
  ggtitle("Box Plot entre CLASE y EDAD")+ 
  stat_compare_means(comparisons = list(c("NO", "SI")), method = "t.test")
```

```{r}
fligner.test(EDAD ~ CLASE, data = datos)
```

```{r}
leveneTest(EDAD ~ CLASE, data = datos, center = "median")
```

Pasemos ahora a las variables categóricas.
Utilizaremos gráficos de barras para interpretar qué niveles de la variable independiente tienen una mayor influencia en la variable dependiente.
El gráfico de barras nos permite comparar visualmente la distribución de la variable dependiente entre las distintas categorías de la variable independiente e identificar posibles patrones o diferencias.

En el caso del tipo de vivienda, tener Propiedad hipotecada y Propiedad libre parece tener mucha más influencia en el pago del préstamo que otras.
Vivir con la familia también tiene cierta influencia en los préstamos pagados.

```{r}
ggplot(datos, aes( x = CLASE)) + 
  geom_bar(colour = "darkorchid4",fill = "lightblue") + 
  facet_grid(. ~ TIPO_VIVIENDA) +
  ggtitle("Préstamo pagado o no vs tipo de vivienda")
```

En el caso de la Nacionalidad, parece que influye más ser español que extranjero, ya que la mayoría de los españoles han devuelto sus préstamos.

```{r}
ggplot(datos, aes( x = CLASE)) + 
  geom_bar(colour = "darkorchid4",fill = "lightblue") + 
  facet_grid(. ~ NACIONALIDAD) +
  ggtitle("Préstamo pagado o no vs nacionalidad")
```

En caso de estado civil, ser casado y soltero parece influir en que se pague el préstamo.
Separado no tiene mucha influencia en si el préstamo se paga o no.

```{r}
ggplot(datos, aes( x = CLASE)) + 
  geom_bar(colour = "darkorchid4",fill = "lightblue") + 
  facet_grid(. ~ ESTADO_CIVIL) +
  ggtitle("Préstamo pagado o no vs estado civil")
```

En nuestros análisis hasta ahora podemos decir que muchas variables han mostrado una buena asociación o influencia en la explicación de la variable dependiente.
**VALOR_VIVIENDA,IMPORTE,CUOTA,INGRESOS,SALDO** todas ellas tienen una p-value más baja y sugieren que son significativas a la hora de explicar si el préstamo se paga o no.
Por otro lado, las variables categóricas PATRIMONIO,EDAD mostraron resultados no significativos.

Considerando las variables categóricas,**TIPO_VIVIENDA,NACIONALIDAD,ESTADO_CIVIL** todas han mostrado alguna asociación con CLASE.

# - [Imputación de los valores ausentes]{style="color:#D35400"}

En primer lugar vamos a ver qué datos faltan de diferentes maneras.

Usando la función básica de R.

```{r}
sapply(datos,
function(x) sum(is.na(x)))
```

Usando plot_missing() de la librería dataExplorer

```{r}
plot_missing(datos)
```

Como podemos ver en los resultados anteriores, en nuestro conjunto de datos faltan datos.
Ahora procederemos a comprobar si siguen algún patrón o mantienen la estructura y los trataremos en consecuencia.

```{r}
md.pattern(datos, rotate.names = T)
```

Podemos ver que faltan valores en dos variables: EDAD e INGRESOS.
La tabla anterior muestra que en 1504 filas todas las variables están presentes.
En 80 filas todas las variables están presentes excepto INGRESOS.
De forma similar, en 58 filas sólo falta EDAD y en 4 filas faltan EDAD e INGRESOS.
También podemos ver los datos ausentes utilizando la librería VIM.
Aquí podemos ver el porcentaje de valores ausentes en cada variable.

```{r}
aggr(datos,col = c('navyblue','red'),numbers = T,sortVars = T,labels = names(datos),
     cex.axis = 0.7,gap = 3,ylab = c("hist de valores perdidos","estructura"))
```

Después de ver los valores ausentes que tenemos en nuestro conjunto de datos, no se observa ningún patrón visible aquí.Debemos comprobar su aleatoriedad y para ello, utilizamos la librería Naniar.

```{r}
mcar_test(datos)
```

El valor p de 0,163408 sugiere que no podemos rechazar la hipótesis nula de MCAR a un nivel de significación de 0,05, lo que significa que los datos ausentes en el conjunto de datos faltan completamente al azar.

Antes de proceder a la imputación del conjunto de datos, es una buena práctica ver los resultados antes y después de dicha imputación, por lo que registramos el valor medio de cada columna sin tener en cuenta los valores que faltan para compararlos después de la imputación.

```{r}
datos_sinNA_num = na.omit(datos_num)

dim(datos_sinNA_num)
```

```{r}
sum(is.na(datos_sinNA_num))
```

```{r}
round(apply(datos_sinNA_num, 2, mean),2)
```

<h4 style="color:#0000FF">

Imputación de los valores ausentes

</h4>

Ahora podemos proceder a imputar los datos que faltan.

Para ello vamos a utilizar tres métodos diferentes:

1.Método PMM(predictive mean matching ) de la librería mice.

2.Metodo árboles CART de la librería mice.

3.Los K-vecinos, de la librería DMwR.

Utilizando el método PMM:

```{r}
imputed_data_pmm = mice(datos,m=5,verbose=T) #El método pmm está por defecto en MICE
```

Comprobamos qué método se ha utilizado:

```{r}
imputed_data_pmm$meth
```

Imputación del conjunto de datos

```{r}
datos_imputados_pmm = complete(imputed_data_pmm)
```

Podemos ver que ya no faltan datos.

```{r}
sapply(datos_imputados_pmm, function(x) sum(is.na(x)))
```

```{r}
dim(datos_imputados_pmm)
```

```{r}
datos_numNA_pmm= subset(datos_imputados_pmm, select = c("VALOR_VIVIENDA","PATRIMONIO","IMPORTE","CUOTA","INGRESOS","SALDO","EDAD")) #Selecting numerical variables to later compare their means
```

Ahora comparamos las variables del conjunto de datos original -sin los NA- frente a las del conjunto completo con los datos imputados.

```{r}
par(mfrow=c(1,2))
plot(density(datos$EDAD,na.rm = T),col=2,main="Variable EDAD. Método pmm")
lines(density(datos_imputados_pmm$EDAD),col=3)
plot(density(datos$INGRESOS,na.rm = T),col=2,main="Variable INGRESOS. Método pmm")
lines(density(datos_imputados_pmm$INGRESOS),col=3)
```

Pasando a nuestro segundo método, utilizamos Metodo árboles CART de librería MICE.

```{r}
imputed_data_cart <- mice(datos, meth = "cart", minbucket = 4)
```

```{r}
datos_imputados_cart = complete(imputed_data_cart)
datos_numNA_cart= subset(datos_imputados_cart, select = c("VALOR_VIVIENDA","PATRIMONIO","IMPORTE","CUOTA","INGRESOS","SALDO","EDAD"))
```

```{r}
par(mfrow=c(1,2))
plot(density(datos$EDAD,na.rm = T),col=2,main="Variable EDAD. Método CART")
lines(density(datos_imputados_cart$EDAD),col=3)
plot(density(datos$INGRESOS,na.rm = T),col=2,main="Variable INGRESOS. Método CART")
lines(density(datos_imputados_cart$INGRESOS),col=3)
```

Nuestro tercer enfoque es a través de los K-vecinos, de la librería DMwR.

```{r}
datos_imputados_knn = knnImputation(datos)


datos_numNA_knn= subset(datos_imputados_knn, select = c("VALOR_VIVIENDA","PATRIMONIO","IMPORTE","CUOTA","INGRESOS","SALDO","EDAD"))


# Comprobamos que ya no existen valores ausentes

sapply(datos_imputados_knn, function(x) sum(is.na(x)))
```

```{r}
par(mfrow=c(1,2))
plot(density(datos$EDAD,na.rm = T),col=2,main="Variable EDAD. Método knn")
lines(density(datos_imputados_knn$EDAD),col=3)
plot(density(datos$INGRESOS,na.rm = T),col=2,main="Variable INGRESOS. Método knn")
lines(density(datos_imputados_knn$INGRESOS),col=3)
```

Observando las representaciones gráficas anteriores, no podemos concluir qué método da mejores resultados, ya que todos ellos captan bien los patrones subyacentes y la variabilidad de los datos.
Procedamos a comparar las medias de cada variable de todos los métodos que hemos utilizado y también con los datos originales sin considerar sus valores ausentes.

```{r}
print("Medias de las variables numéricas originales")
round(apply(datos_sinNA_num, 2, mean, na.rm=TRUE),2)
```

```{r}
print("Medias de las variables numéricas. Método PMM")
round(apply(datos_numNA_pmm, 2, mean),2)
```

```{r}
print("Medias de las variables numéricas. Árbol CART")
round(apply(datos_numNA_cart, 2, mean),2)
```

```{r}
print("Medias de las variables numéricas. Método K-Vecinos")
round(apply(datos_numNA_knn, 2, mean),2)
```

Si se comparan las medias de los datos originales y de los datos imputados por los tres métodos diferentes, se observa que las medias de los datos imputados por los tres métodos se aproximan mucho a las medias de los datos originales.
Sin embargo, las medias de los datos imputados por el método k-vecinos están ligeramente más cerca de las medias de los datos originales que las de los otros dos métodos.


Por lo tanto, basándonos en las medias de los datos imputados, podemos concluir que el método de imputación K-NN puede utilizarse para imputar valores ausentes en el conjunto de datos dado.

# - [Tratamiento de los valores anómalos]{style="color:#D35400"}

Los valores atípicos suelen identificarse como observaciones que se alejan del resto de los puntos de datos.
Para encontrar valores atípicos en nuestro conjunto de datos existen muchos métodos.
En nuestro caso, ninguno de los niveles de las variables categóricas tiene una proporción demasiado baja en los datos, por lo que consideraremos variables numéricas imputadas con el método k-vecinos.

```{r}
par(mfrow=c(2,4))
boxplot(datos_numNA_knn$VALOR_VIVIENDA)
boxplot(datos_numNA_knn$PATRIMONIO)
boxplot(datos_numNA_knn$IMPORTE)
boxplot(datos_numNA_knn$CUOTA)
boxplot(datos_numNA_knn$INGRESOS)
boxplot(datos_numNA_knn$SALDO)
boxplot(datos_numNA_knn$EDAD)
```

Usamos las funciones diagnose_outlier y plot_outlier de la librería dlookr.
Esto nos da una información muy buena y detallada acerca de los valores atípicos.Esto también muestra el cambio en los datos **con y sin valores atípicos** simultáneamente.

```{r}
variables <- c("VALOR_VIVIENDA","PATRIMONIO","IMPORTE","CUOTA","INGRESOS","SALDO","EDAD")

datos_imputados_knn %>%  diagnose_outlier(variables)

datos_imputados_knn %>%  plot_outlier()

datos_imputados_knn %>%   target_by(CLASE) %>%   plot_outlier(variables)
```

Dado que el tema del tratamiento de los valores atípicos es muy delicado,depende de nuestro objetivo de análisis y también de cómo se haya mantenido el conjunto de datos, debemos ser conscientes de no modificar demasiado el conjunto de datos.En la práctica, preprocesar los datos tratando los valores atípicos tiende a producir resultados más precisos en presencia de datos no vistos.
En nuestro caso, utilizaremos dos métodos para tratar los valores atípicos.

1.**Método Tukey**: Este método marca los valores atípicos teniendo en cuenta los valores de los cuartiles, Q1, Q2 y Q3, donde Q1 equivale al percentil 25, Q2 al percentil 50 (también conocido como mediana) y Q3 es el percentil 75.
Estamos utilizando **type='stop'** ya que esto convertirá los valores fuera del umbral en umbral.
Si tuviéramos que convertirlos en 'NA', habríamos utilizado **type="set_na"**, pero como ya hemos tratado los valores que faltan y además necesitamos este modelo para la modelización predictiva, sustituiremos los valores atípicos por valores umbral.

```{r}

set.seed(10) 

df_tukey=prep_outliers(data = datos_imputados_knn, input = variables, type='stop', method = "tukey")

```

2.**Reemplazando los valores atípicos por la mediana**.

```{r}
set.seed(10) 
#Identificar los valores atípicos y sustituirlos por la mediana
df_median = datos_imputados_knn  #hacer una copia de los datos
cols <- names(df_median)[sapply(df_median, is.numeric)]
for (i in cols) {
  q1 <- quantile(df_median[[i]], 0.25)
  q3 <- quantile(df_median[[i]], 0.75)
  iqr <- q3 - q1
  fence1 <- q1 - 1.5 * iqr
  fence2 <- q3 + 1.5 * iqr
  outliers <- df_median[[i]] < fence1 | df_median[[i]] > fence2
  if (any(outliers)) {
    df_median[outliers, (i) := median(df_median[[i]], na.rm = TRUE)]
  }
}

```

Ahora se comparan las estadísticas de los datos originales y los datos obtenidos después de tratarlos con dos métodos.

```{r}
profiling_num(datos_imputados_knn) %>% select(variable, mean, std_dev, variation_coef) #datos antes de la imputación
```

```{r}
profiling_num(df_tukey) %>% select(variable, mean, std_dev, variation_coef) #Datos tras aplicar el método tukey
```

```{r}
profiling_num(df_median) %>% select(variable, mean, std_dev, variation_coef)#Datos tras aplicar el método de la mediana

```

Hemos aplicado dos métodos de imputación de valores atípicos y hemos comparado sus resultados.
Observamos que no hay mucha diferencia en general cuando se aplica el método Tukey y los valores atípicos se han sustituido por valores umbral, sólo unas pocas variables muestran diferencias en los valores medios.
Por otra parte, los valores medios cuando los valores atípicos se sustituyen por medianas, son mucho más similares a los valores antes de la imputación.
En el caso de la variable PATRIMONIO, el valor medio es cero porque hay demasiados ceros en los datos.
Podemos ignorarlos porque no me parece lógico sustituirlos por ningún otro valor.
Dado que los resultados son algo similares a los del conjunto de datos original sin imputación, seguiremos adelante únicamente con este ultimo conjunto de datos(datos_imputados_knn).

# - [Equilibrado de la muestra]{style="color:#D35400"}

Antes de proceder al equilibrado de la muestra, vamos a tomar sólo aquellas variables que son significativas para predecir la CLASE

```{r}
modelo = glm(CLASE ~., data = datos_imputados_knn, family = "binomial")
summary(modelo)
```

```{r}
library(broom)
tidy(modelo)

```

También podemos utilizar el software WEKA para la selección de variables.
A continuación, se muestra una imagen con el resultado de haber aplicado un método Ranker.

<div>

<p style="text-align:center;">

<img src="C:/Users/SM/Desktop/Big Data UNED/Modulo 1/Practical/weka.jpg" alt="Selección de variables Método Ranker con WeKA" width="1000px" height="900px"/>

</p>

</div>

Las dos formas de la selección de variables me dieron resultados diferentes.
Basándome en ambos resultados, sólo voy a dejar fuera las variables EDAD,INGRESOS,PATRIMONIO.
Estas variables se excluirán al obtener una muestra equilibrada utilizando el método del cubo.

Antes de realizar el método del cubo recordamos con una simple tabla los registros de nuestra variable de clasificación, CLASE.

```{r}
t2 <- table(datos_imputados_knn$CLASE)
addmargins(t2)
```

<h4 style="color:#0000FF">

Muestreo aleatorio

</h4>

```{r}
datos1482 <- subset(datos_imputados_knn, CLASE == "SI")
datos164 <- subset(datos_imputados_knn, CLASE == "NO")

#Tamaño de la muestra
n <-164
set.seed(0)
muestra <- sample(1:nrow(datos1482),size=n,replace=FALSE)
muestra164 <- datos1482[muestra, ]
datos_aleatorios_328 <- rbind(muestra164, datos164) #Muestra final 1

# Conjunto de datos equilibrado
summary(datos_aleatorios_328)
head(datos_aleatorios_328)
```

<h4 style="color:#0000FF">

Muestreo con el método del cubo.

</h4>

```{r}
# Datos donde efectuamos la selección de las transacciones datos_SIs
datos_SI = datos_imputados_knn[ datos_imputados_knn$CLASE == "SI", ]


# Número de transacciones datos_SI
datos_SIs = nrow(datos_SI)


# Creamos las variables indicadores para cada una de las variables de equilibrio. 
# Variable que vale 1 en todas las partes (para comprobar la estimación del tamaño poblacional)
UNO = rep(1, datos_SIs) 


# Variables cuantitativas
X1 = datos_SI[ , c("VALOR_VIVIENDA", "IMPORTE", "SALDO", "CUOTA")]

# Variables cualitativas
X2 <- disjunctive(datos_SI$TIPO_VIVIENDA)
colnames(X2) <- levels(datos_SI$TIPO_VIVIENDA)
X3 <- disjunctive(datos_SI$NACIONALIDAD)
colnames(X3) <- levels(datos_SI$NACIONALIDAD)
X4 <- disjunctive(datos_SI$ESTADO_CIVIL)
colnames(X4) <- levels(datos_SI$ESTADO_CIVIL)

# Matriz de diseño
X = as.matrix(cbind(UNO, X1,X2,X3,X4))


# Tamaño de la muestra
s.datos = 164


# Probabilidades de inclusión
pik = rep(s.datos / datos_SIs, datos_SIs)


# extracción de la muestra
# method = 2 para una fase de aterrizaje por supresión de variables
# order =1 los datos se ordenan aleatoriamente

set.seed(012)
s = samplecube( X, pik, method = 2, order = 1, comment = FALSE )


# Generación de fichero resultante
muestra.datos_SI = cbind( datos_SI, s )
muestra.datos_SI = muestra.datos_SI[ muestra.datos_SI$s == 1, ]
muestra.datos_SI$s  = NULL


```

Debemos comprobar la calidad de nuestro muestreo, para lo cual recurrimos a los estimadores de Horvitz-Thompson y vemos, en la última columna, la desviación de cada media en porcentaje.
En este caso, sólo dos niveles "otros" y "Separados" de diferentes variables han mostrado alguna desviación en sus valores medios.
Sin embargo, para la mayoría de las variables no hay mucha desviación.

```{r}
# Calidad de la muestra obtenida

Totales = apply(X, 2, sum)

Horvitz.Thompson =  apply(X * s / pik, 2, sum)

calidad =  cbind.data.frame(Totales, Horvitz.Thompson)

calidad$Desv.Abs. =  round(calidad$Totales - calidad$Horvitz.Thompson, 2)

calidad$Desv.Rel. =  round((calidad$Totales / calidad$Horvitz.Thompson - 1) *100, 2)

print(as.matrix.data.frame(calidad))
```

No utilizo el método SMOTE porque no es necesario un sobremuestreo de la clase minoritaria, ya que dispongo de 164 observaciones para obtener un conjunto de muestras equilibradas de 328.
Además, me parece más lógico conservar las observaciones originales que crear muestras sintéticas, ya que así se evitan los sesgos.

```{r}
# Fichero final con las muestras balanceadas

# Conjunto de datos resultante

datos_mdc_328 = rbind(muestra.datos_SI, datos164)  #Muestra final 2

dim(datos_mdc_328)

# Tabla de frecuencias de la variable dependiente para observar que los datos están ya balanceados

table(datos_mdc_328$CLASE)
```

<h4 style="color:#0000FF">

Comparación de variables 

</h4>


Ahora vamos a comparar las dos muestras con los datos originales y comprobar si hay muchas diferencias en sus parametros.

Variable: IMPORTE

Considerando la variable numérica IMPORTE y analizando los resultados obtenidos, podemos observar que la media y la mediana de los datos originales sin imputación difiere de la de esas dos muestras obtenidas por métodos diferentes.
Sin embargo, los resultados de las dos muestras son algo similares.

```{r}

data1_var <- pull(datos_imputados_knn, "IMPORTE")
data2_var <- pull(datos_aleatorios_328, "IMPORTE")
data3_var <- pull(datos_mdc_328, "IMPORTE")

set.seed(0)
sumario <- tibble(
  Datos = c("Datos originales", "Datos equilibrados con selección aleatoria", "Datos equilibrados con muestra del método del cubo"),
  Media = c(mean(data1_var), mean(data2_var), mean(data3_var)),
  Mediana = c(median(data1_var), median(data2_var), median(data3_var))
)

sumario
```

```{r}

par(mfrow = c(1, 3))
mean1 <- mean(datos_imputados_knn$IMPORTE)
mean2 <- mean(datos_aleatorios_328$IMPORTE)
mean3 <- mean(datos_mdc_328$IMPORTE)

median1 <- median(datos_imputados_knn$IMPORTE)
median2 <- median(datos_aleatorios_328$IMPORTE)
median3 <- median(datos_mdc_328$IMPORTE)


ggplot(datos_imputados_knn, aes(x = IMPORTE)) +
  geom_histogram(binwidth = 500, color = "black", fill = "white") +
  geom_vline(aes(xintercept = mean1), color = "blue", linetype = "dashed", size = 1) +
  geom_vline(aes(xintercept = median1), color = "red", linetype = "dashed", size = 1) +
  labs(title = "Datos originales",
       x = "IMPORTE", y = "Frecuencia")+
  scale_x_continuous(limits = c(0, 30000))

ggplot(datos_aleatorios_328, aes(x = IMPORTE)) +
  geom_histogram(binwidth = 500, color = "black", fill = "white") +
  geom_vline(aes(xintercept = mean2), color = "blue", linetype = "dashed", size = 1) +
  geom_vline(aes(xintercept = median2), color = "red", linetype = "dashed", size = 1) +
  labs(title = "Datos equilibrados con selección aleatoria",
       x = "IMPORTE", y = "Frecuencia")

ggplot(datos_mdc_328, aes(x = IMPORTE)) +
  geom_histogram(binwidth = 500, color = "black", fill = "white") +
  geom_vline(aes(xintercept = mean3), color = "blue", linetype = "dashed", size = 1) +
  geom_vline(aes(xintercept = median3), color = "red", linetype = "dashed", size = 1) +
  labs(title = "Datos equilibrados con método de cubo",
       x = "IMPORTE", y = "Frecuencia")
```

Variable: TIPO_VIVIENDA

Considerando la variable categórica TIPO_VIVIENDA y observando los resultados obtenidos, podemos comparar la frecuencia y el porcentaje de niveles de la variable obtenidos en los tres casos.
Podemos observar que mientras en la base de datos original los diferentes niveles estaban distribuidos de forma desigual, en el caso de las muestras equilibradas, en ambos casos los datos están distribuidos de forma más uniforme.
Aunque ninguno de los métodos de muestreo puede considerarse mejor que otro, cada método tiene sus pros y sus contras.

```{r}
par(mfrow = c(1, 3))
freq(datos_imputados_knn$TIPO_VIVIENDA)
freq(datos_aleatorios_328$TIPO_VIVIENDA)
freq(datos_mdc_328$TIPO_VIVIENDA)
```
